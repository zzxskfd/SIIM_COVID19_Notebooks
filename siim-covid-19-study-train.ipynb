{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install tqdm"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting tqdm\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/0b/e8/d6f4db0886dbba2fc87b5314f2d5127acdc782e4b51e6f86972a2e45ffd6/tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 5.0 MB/s \n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.62.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import shutil, os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "# from tf.keras.metrics import AUC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !unzip -q siimcovid19-512-jpg-image-dataset.zip -d siimcovid19-512-jpg-image-dataset/"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "fold_index = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataset_dir = '/mnt/siim-covid19/siimcovid19-512-jpg-image-dataset/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_df_from_original_file():\n",
    "    # make sure using original siimcovid19-512-jpg-image-dataset\n",
    "    train_df = pd.read_csv(dataset_dir + 'train.csv')\n",
    "    train_df['image_path'] = dataset_dir + 'train/' + train_df.image_id + '.jpg'\n",
    "    # split\n",
    "    gkf = GroupKFold(n_splits = 5)\n",
    "    train_df['fold'] = -1\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):\n",
    "        train_df.loc[val_idx, 'fold'] = fold\n",
    "    return train_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Use saved file\n",
    "train_df_path = '/mnt/siim-covid19/output/study_train_df_with_cur_loc.csv'\n",
    "if (os.path.exists(train_df_path)):\n",
    "    train_df = pd.read_csv(train_df_path)\n",
    "else:\n",
    "    train_df = get_df_from_original_file()\n",
    "\n",
    "train_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                              boxes  \\\n",
       "0           0  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1           1                                                NaN   \n",
       "2           2  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3           3  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4           4  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "\n",
       "       image_id  Negative for Pneumonia  Typical Appearance  \\\n",
       "0  000a312787f2                       0                   1   \n",
       "1  000c3a3f293f                       1                   0   \n",
       "2  0012ff7358bc                       0                   1   \n",
       "3  001398f4ff4f                       0                   0   \n",
       "4  001bd15d1891                       0                   1   \n",
       "\n",
       "   Indeterminate Appearance  Atypical Appearance  \\\n",
       "0                         0                    0   \n",
       "1                         0                    0   \n",
       "2                         0                    0   \n",
       "3                         0                    1   \n",
       "4                         0                    0   \n",
       "\n",
       "                                            filepath  \\\n",
       "0  /kaggle/input/siim-covid19-detection/train/577...   \n",
       "1  /kaggle/input/siim-covid19-detection/train/ff0...   \n",
       "2  /kaggle/input/siim-covid19-detection/train/9d5...   \n",
       "3  /kaggle/input/siim-covid19-detection/train/28d...   \n",
       "4  /kaggle/input/siim-covid19-detection/train/dfd...   \n",
       "\n",
       "                                          image_path  fold  \n",
       "0  /mnt/siim-covid19/siimcovid19-512-jpg-image-da...     4  \n",
       "1  /mnt/siim-covid19/siimcovid19-512-jpg-image-da...     0  \n",
       "2  /mnt/siim-covid19/siimcovid19-512-jpg-image-da...     4  \n",
       "3  /mnt/siim-covid19/siimcovid19-512-jpg-image-da...     1  \n",
       "4  /mnt/siim-covid19/siimcovid19-512-jpg-image-da...     3  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>filepath</th>\n",
       "      <th>image_path</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/siim-covid19-detection/train/577...</td>\n",
       "      <td>/mnt/siim-covid19/siimcovid19-512-jpg-image-da...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/siim-covid19-detection/train/ff0...</td>\n",
       "      <td>/mnt/siim-covid19/siimcovid19-512-jpg-image-da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/siim-covid19-detection/train/9d5...</td>\n",
       "      <td>/mnt/siim-covid19/siimcovid19-512-jpg-image-da...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/input/siim-covid19-detection/train/28d...</td>\n",
       "      <td>/mnt/siim-covid19/siimcovid19-512-jpg-image-da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/siim-covid19-detection/train/dfd...</td>\n",
       "      <td>/mnt/siim-covid19/siimcovid19-512-jpg-image-da...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# move files and change records\n",
    "class_names = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n",
    "for class_name in class_names:\n",
    "    os.makedirs(dataset_dir + 'train/' + class_name, exist_ok = True)\n",
    "    os.makedirs(dataset_dir + 'val/' + class_name, exist_ok = True)\n",
    "\n",
    "for index, row in tqdm(train_df.iterrows()):\n",
    "    # filename = file_path.split('/')[-1].split('.')[0]\n",
    "    # if (filename + '_image' != row.id):\n",
    "    #     continue\n",
    "    file_path = row.image_path\n",
    "\n",
    "    is_val = (row.fold == fold_index)\n",
    "    train_or_val = 'val' if is_val else 'train'\n",
    "    class_name = class_names[row[class_names].to_list().index(1)]\n",
    "    filename = row.image_id\n",
    "\n",
    "    target_path = dataset_dir + train_or_val + '/' + class_name + '/' + filename + '.jpg'\n",
    "    if (file_path == target_path):\n",
    "        continue\n",
    "    shutil.move(file_path, target_path)\n",
    "    # print(file_path)\n",
    "    # print(target_path)\n",
    "    train_df.loc[index, 'image_path'] = target_path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save train_df\n",
    "train_df.to_csv(train_df_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_dir = dataset_dir + 'train/'\n",
    "validation_dir = dataset_dir + 'val/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inception"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "input_dim = 299\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 32, class_mode = 'categorical', target_size = (input_dim, input_dim))\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, batch_size = 32, class_mode = 'categorical', target_size = (input_dim, input_dim))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "base_model = InceptionV3(input_shape = (input_dim, input_dim, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(4, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "# model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inc_history = model.fit(train_generator, validation_data = validation_generator, epochs = 10, steps_per_epoch=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet50"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
    "validation_generator = test_datagen.flow_from_directory( validation_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
    "base_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "base_model.compile(optimizer = tf.keras.optimizers.SGD(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "resnet_history = base_model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EfficientNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -U efficientnet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
    "validation_generator = test_datagen.flow_from_directory( validation_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def build_model(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "eff_history = model_final.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ViT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('myconda': conda)"
  },
  "interpreter": {
   "hash": "d92835af267f429f30bd9d9d5f3cd52063e0ca033b4a27de3ed439288b8f7359"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}